{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnhenryrudden/anaconda3/envs/shaky_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from encoding import EncodingManager, create_encoding_dataloader\n",
    "import encoding as encoding_module\n",
    "import utils\n",
    "from gan import Generator, Discriminator, train as train_gan\n",
    "import gan as gan_module\n",
    "import torch\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import ngram as ngram_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['First', 'Citizen', ':'],\n",
       " ['Before',\n",
       "  'we',\n",
       "  'proceed',\n",
       "  'any',\n",
       "  'further',\n",
       "  ',',\n",
       "  'hear',\n",
       "  'me',\n",
       "  'speak',\n",
       "  '.']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BY_CHAR = True\n",
    "TRAIN_PATH = 'data/raw_train.txt'\n",
    "LOG_DIR_BASE = './runs/'\n",
    "tokenized_sentences = utils.process_data(TRAIN_PATH, add_unks=not(BY_CHAR))\n",
    "tokenized_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sentence has 20 tokens\n"
     ]
    }
   ],
   "source": [
    "sentence_lengths = [len(sentence) for sentence in tokenized_sentences]\n",
    "longest_sentence = max(tokenized_sentences, key=len)\n",
    "avg_word_length = np.mean([len(word) for sentence in tokenized_sentences for word in sentence])\n",
    "print(f'Longest sentence has {len(longest_sentence)} tokens')\n",
    "SEQ_LENGTH = int(len(longest_sentence) * avg_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraction_of_seq_lengths = {k: v / len(sentence_lengths) for k, v in Counter(sentence_lengths).items()}\n",
    "plt.bar(fraction_of_seq_lengths.keys(), fraction_of_seq_lengths.values(), label='Seq Length distribution')\n",
    "plt.xticks(np.arange(0, len(longest_sentence), 1))\n",
    "plt.xlabel('Sentence length')\n",
    "plt.savefig('./figs/seq_length_distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = tokenized_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Dataloader checks\n",
    "\n",
    "Double check one hot encoding and decoding is working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys loaded successfully from data/char_to_index.json\n"
     ]
    }
   ],
   "source": [
    "ENCODING_MANAGER_PATH = 'data/word_to_index.json'\n",
    "if BY_CHAR:\n",
    "    ENCODING_MANAGER_PATH = 'data/char_to_index.json'\n",
    "encoding_manager = EncodingManager(ENCODING_MANAGER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding sentence: ['W', 'e', ' ', 'h', 'a', 'v', 'e', ' ', 'l', 'e', 'd', ' ', 's', 'i', 'n', 'c', 'e', ' ', 't', 'h', 'y', ' ', 'e', 'x', 'i', 'l', 'e', ' ', '.', ' ', 'T', 'h', 'i', 'n', 'k', ' ', 'w', 'i', 't', 'h', ' ', 't', 'h', 'y', 's', 'e', 'l', 'f', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Encoding sentence: ['F', 'a', 'm', 'e', ' ', ',', ' ', 'a', 't', ' ', 't', 'h', 'e', ' ', 'w', 'h', 'i', 'c', 'h', ' ', 'h', 'e', ' ', 'a', 'i', 'm', 's', ' ', ',', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Encoding sentence: ['G', 'o', 'o', 'd', ' ', 'e', 'v', 'e', 'n', ' ', ',', ' ', 'g', 'o', 'o', 'd', ' ', 'f', 'a', 't', 'h', 'e', 'r', ' ', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Encoding sentence: ['B', 'u', 't', ' ', 'i', 't', ' ', 'c', 'o', 'n', 'f', 'o', 'u', 'n', 'd', 's', ' ', 't', 'h', 'e', ' ', 'b', 'r', 'e', 'a', 't', 'h', 'e', 'r', ' ', '.', ' ', 'H', 'e', ' ', 's', 'h', 'o', 'u', 'l', 'd', ' ', 'h', 'a', 'v', 'e', ' ', 'l', 'i', 'v', 'e', 'd', ' ', ',', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "first batch sentence: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "decoded first sentence: ['W', 'e', ' ', 'h', 'a', 'v', 'e', ' ', 'l', 'e', 'd', ' ', 's', 'i', 'n', 'c', 'e', ' ', 't', 'h', 'y', ' ', 'e', 'x', 'i', 'l', 'e', ' ', '.', ' ', 'T', 'h', 'i', 'n', 'k', ' ', 'w', 'i', 't', 'h', ' ', 't', 'h', 'y', 's', 'e', 'l', 'f', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_encoding_dataloader(tokenized_data, encoding_manager, seq_length=SEQ_LENGTH, batch_size=4, by_char=True, verbose=True)\n",
    "batch = next(iter(dataloader))\n",
    "print(f'first batch sentence: {batch[0]}')\n",
    "encoded_first_sentence = batch[0]\n",
    "decoded_first_sentence = [encoding_manager.decode_one_hot(encoded_token) for encoded_token in encoded_first_sentence]\n",
    "print(f'decoded first sentence: {decoded_first_sentence}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_to_encode = ['That', 'you', 'have', \"ta'en\", 'a', 'tardy', '<UNK>', 'here', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
    "# encoded_sentence = [word2vec_manager.one_hot_encode(word) for word in sentence_to_encode]\n",
    "# decoded = [word2vec_manager.decode_one_hot(one_hot) for one_hot in encoded_sentence]\n",
    "# encoded_sentence,decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "seq_length = SEQ_LENGTH \n",
    "\n",
    "# Generator first\n",
    "\n",
    "gen_input_dim = len(encoding_manager.word_to_index) + 1 # add 1 to input dim to account for padding token\n",
    "gen_hidden_dim = 300\n",
    "\n",
    "# add 1 to output dim to account for padding token\n",
    "gen_output_dim = len(encoding_manager.word_to_index) + 1\n",
    "\n",
    "generator = Generator(input_size=gen_input_dim, hidden_size=gen_hidden_dim, output_size=gen_output_dim, seq_length=seq_length)\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "# Discriminator input is the same as the generator output (the generated next token probability distribution)\n",
    "discrim_input_dim = gen_output_dim\n",
    "discrim_hidden_dim = 100\n",
    "\n",
    "discriminator = Discriminator(input_dim=discrim_input_dim, hidden_dim=discrim_hidden_dim, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator has 461466 parameters\n",
      "Discriminator has 67301 parameters\n"
     ]
    }
   ],
   "source": [
    "discrim_params = list(discriminator.parameters())\n",
    "gen_params = list(generator.parameters())\n",
    "num_params_gen = sum([np.prod(p.size()) for p in gen_params])\n",
    "num_params_discrim = sum([np.prod(p.size()) for p in discrim_params])\n",
    "print(f'Generator has {num_params_gen} parameters')\n",
    "print(f'Discriminator has {num_params_discrim} parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "batch_size = 4\n",
    "temperature = 1.0\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_epochs = 1\n",
    "TRAIN_AND_VAL_FRAC = 0.5\n",
    "if TRAIN_AND_VAL_FRAC != 1.0:\n",
    "    train_val, rest = train_test_split(tokenized_data, train_size=TRAIN_AND_VAL_FRAC, random_state=42)\n",
    "    train_set, val_set = train_test_split(train_val, train_size=0.8, random_state=42)\n",
    "else:\n",
    "    train_set, val_set = train_test_split(tokenized_data, train_size=0.9, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentences(generator, temp):\n",
    "    gens = []\n",
    "    for i in range(10):\n",
    "        noise = torch.randn(1, seq_length, gen_input_dim)\n",
    "        generated_data = generator(noise, temperature, hard=False)\n",
    "        argmaxs = torch.argmax(generated_data[0], dim=1)\n",
    "        generated_sentence = [encoding_manager.index_to_word(index) for index in argmaxs]\n",
    "        gens.append(\" \".join(generated_sentence).replace(\"<PAD>\", \"\"))\n",
    "    return gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hyperparams(possible_hyperparams, num_epochs, train_set, val_set, encoding_manager, metrics_dir, calc_perplexity):\n",
    "    assert len(possible_hyperparams.keys()) == 3 and set(possible_hyperparams.keys()) == set(['lr', 'temp', 'batch_size'])\n",
    "    num_iterations = np.prod([len(possible_hyperparams[key]) for key in possible_hyperparams.keys()])\n",
    "    current_iteration = 0\n",
    "    results = []\n",
    "    for lr in possible_hyperparams['lr']:\n",
    "        for temp in possible_hyperparams['temp']:\n",
    "            for batch_size in possible_hyperparams['batch_size']:\n",
    "                current_iteration += 1\n",
    "                print(f'Iteration {current_iteration} of {num_iterations}')\n",
    "                print(f'lr={lr}, temp={temp}, batch_size={batch_size}, seq_length={seq_length}')\n",
    "                generator = Generator(input_size=gen_input_dim, hidden_size=gen_hidden_dim, output_size=gen_output_dim, seq_length=seq_length)\n",
    "                discriminator = Discriminator(input_dim=discrim_input_dim, hidden_dim=discrim_hidden_dim, seq_length=seq_length)\n",
    "                g_loss, d_loss =train_gan(\n",
    "                        generator=generator,\n",
    "                        discriminator=discriminator,\n",
    "                        generator_lr = lr,\n",
    "                        discriminator_lr = lr,\n",
    "                        validation_sentences=val_set,\n",
    "                        training_sentences=train_set,\n",
    "                        word_encoding_manager=encoding_manager,\n",
    "                        calc_perplexity=calc_perplexity,\n",
    "                        seq_length=SEQ_LENGTH,\n",
    "                        generator_input_features=gen_input_dim,  # Updated parameter name\n",
    "                        num_epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        noise_sample_method=\"normal\",\n",
    "                        gumbel_hard=True,\n",
    "                        temperature=temp,\n",
    "                        device=device,\n",
    "                        by_char=BY_CHAR,\n",
    "                        tensorboard_log_dir=metrics_dir\n",
    "                    )\n",
    "                gens = generate_sentences(generator, temp)\n",
    "                results.append((lr, temp, batch_size, seq_length, g_loss, d_loss, generator, discriminator, gens))\n",
    "                print(f'Generated sentences: {gens[:2]}')\n",
    "    return results\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_for_perplexity = ngram_module.NGRAM_Model(4, scoring_method='LI_grid_search')\n",
    "# ngram_for_perplexity.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix NGRAM to work with chars\n",
    "# calc_perplexity = lambda sentences: gan_module.estimate_perplexity(sentences, ngram_for_perplexity)\n",
    "calc_perplexity = lambda sentences: float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def prepare_metrics_dir(log_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    else:\n",
    "        # clear existing logs\n",
    "        for f in os.listdir(log_dir):\n",
    "            if os.path.isdir(os.path.join(log_dir, f)):\n",
    "                shutil.rmtree(os.path.join(log_dir, f))\n",
    "            else:\n",
    "                os.remove(os.path.join(log_dir, f))\n",
    "\n",
    "def run_experiment(possible_hyperparams, experiment_id, num_epochs, train_set, val_set, encoding_manager, calc_perplexity, log_dir_base):\n",
    "    log_dir = os.path.join(log_dir_base, \"hyperparameter_search_\" + experiment_id)\n",
    "    prepare_metrics_dir(log_dir)\n",
    "    results = test_hyperparams(possible_hyperparams, num_epochs, train_set, val_set, encoding_manager, log_dir, calc_perplexity)          \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 1\n",
      "lr=0.0001, temp=1.0, batch_size=32, seq_length=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/366 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Generator Loss: 0.6950 | Discriminator Loss: 1.3863: 100%|██████████| 366/366 [06:49<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentences: ['r x b I N  u                                                                ', 'F 3 , 3 I j t                                                                ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "possible_hyperparams = {\n",
    "        'lr': [0.0001],\n",
    "        'batch_size': [32],\n",
    "        'temp': [1.0],\n",
    "        # 'seq_length': [15],\n",
    "    }\n",
    "\n",
    "test_results = run_experiment(possible_hyperparams, \"test\", num_epochs, train_set, val_set, encoding_manager, calc_perplexity, LOG_DIR_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0001,\n",
       "  1.0,\n",
       "  32,\n",
       "  71,\n",
       "  0.6758459619159907,\n",
       "  1.3740535687879134,\n",
       "  Generator(\n",
       "    (lstm): LSTM(66, 300, batch_first=True)\n",
       "    (fc): Linear(in_features=300, out_features=66, bias=True)\n",
       "    (ls): LogSoftmax(dim=2)\n",
       "  ),\n",
       "  Discriminator(\n",
       "    (lstm): LSTM(66, 100, batch_first=True)\n",
       "    (fc): Linear(in_features=100, out_features=1, bias=True)\n",
       "  ),\n",
       "  ['r x b I N  u                                                                ',\n",
       "   'F 3 , 3 I j t                                                                ',\n",
       "   '- y  . n Q Y                                                                ',\n",
       "   '. Z m u N N   m                                                              ',\n",
       "   'e j G B K !   ? v                                                              ',\n",
       "   \"' P J n P x f  u n d                                                            \",\n",
       "   'Z ! u   p x  q                                                              ',\n",
       "   'j Q n 3 - c  n  n                                                             ',\n",
       "   '. C , D N N c ? u                                                               ',\n",
       "   'G N F  E F X  u                                                              '])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# don't run this cell again\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False # don't run this cell again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_BATCH_MODEL_PATH = './models/generator_batch_size_4.pt'\n",
    "if os.path.exists(BEST_BATCH_MODEL_PATH):\n",
    "    generator = gan_module.load_gen_model(BEST_BATCH_MODEL_PATH, gen_input_dim, gen_hidden_dim, gen_output_dim, seq_length)\n",
    "    batch_size_results = [(0.001, 1.0, 4, 15, 0.0, 0.0, generator, None, generate_sentences(generator, 1.0))]\n",
    "else:\n",
    "    possible_hyperparams = {\n",
    "        'lr': [0.001],\n",
    "        'batch_size': [4, 16, 32],\n",
    "        'temp': [1.0],\n",
    "        'seq_length': [15],\n",
    "    }\n",
    "    batch_size_results = run_experiment(possible_hyperparams, \"batch_size\", num_epochs, train_sents, val_sents, encoding_manager, calc_perplexity, LOG_DIR_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_SEQ_LENGTH_MODEL_PATH = './models/generator_seq_length_13.pt'\n",
    "if os.path.exists(BEST_SEQ_LENGTH_MODEL_PATH):\n",
    "    generator = gan_module.load_gen_model(BEST_SEQ_LENGTH_MODEL_PATH, gen_input_dim, gen_hidden_dim, gen_output_dim, seq_length)\n",
    "    seq_length_results = [(0.001, 1.0, 4, 13, 0.0, 0.0, generator, None, generate_sentences(generator, 1.0))]\n",
    "else:\n",
    "    possible_hyperparams = {\n",
    "        'lr': [0.001],\n",
    "        'batch_size': [16],\n",
    "        'temp': [1.0],\n",
    "        'seq_length': [13,15],\n",
    "    }\n",
    "    seq_length_results = run_experiment(possible_hyperparams, \"seq_length\", num_epochs, train_sents, val_sents, encoding_manager, calc_perplexity, LOG_DIR_BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_TEMP_MODEL_PATH = './models/generator_temp_1.0.pt'\n",
    "if os.path.exists(BEST_TEMP_MODEL_PATH):\n",
    "    generator = gan_module.load_gen_model(BEST_TEMP_MODEL_PATH, gen_input_dim, gen_hidden_dim, gen_output_dim, seq_length)\n",
    "    temp_results = [(0.001, 1.0, 4, 15, 0.0, 0.0, generator, None, generate_sentences(generator, 1.0))]\n",
    "else:\n",
    "    possible_hyperparams = {\n",
    "        'lr': [0.001],\n",
    "        'batch_size': [16],\n",
    "        'temp': [1.0, 1.5],\n",
    "        'seq_length': [15],\n",
    "    }\n",
    "\n",
    "    temp_results = run_experiment(possible_hyperparams, \"temp\", num_epochs, train_sents, val_sents, encoding_manager, calc_perplexity, LOG_DIR_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_LR_MODEL_PATH = './models/generator_lr_0.0001.pt'\n",
    "if os.path.exists(BEST_LR_MODEL_PATH):\n",
    "    generator = gan_module.load_gen_model(BEST_LR_MODEL_PATH, gen_input_dim, gen_hidden_dim, gen_output_dim, seq_length)\n",
    "    lr_results = [(0.0001, 1.0, 16, 15, 0.0, 0.0, generator, None, generate_sentences(generator, 1.0))]\n",
    "else:\n",
    "    possible_hyperparams = {\n",
    "        'lr': [0.0001],\n",
    "        'batch_size': [16],\n",
    "        'temp': [1.0],\n",
    "        'seq_length': [15],\n",
    "    }\n",
    "\n",
    "    lr_results = run_experiment(possible_hyperparams, \"lr\", num_epochs, train_sents, val_sents, encoding_manager, calc_perplexity, LOG_DIR_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCRIM_LOSS_CSV_PATH = 'metrics/Loss _ Train_Discriminator Loss.csv'\n",
    "GEN_LOSS_CSV_PATH = 'metrics/Loss _ Train_Generator Loss.csv'\n",
    "GAN_LOSS_PLOT_PATH = 'figs/gan_loss_plot.png'\n",
    "\n",
    "import pandas as pd\n",
    "discrim_loss_df = pd.read_csv(DISCRIM_LOSS_CSV_PATH)\n",
    "gen_loss_df = pd.read_csv(GEN_LOSS_CSV_PATH)\n",
    "\n",
    "window_size = 40\n",
    "\n",
    "smoothed_discrim_loss = moving_average(discrim_loss_df['Value'], window_size)\n",
    "smoothed_gen_loss = moving_average(gen_loss_df['Value'], window_size)\n",
    "\n",
    "\n",
    "plt.plot(discrim_loss_df['Step'], discrim_loss_df['Value'], alpha=0.2, c='#e52592')\n",
    "plt.plot(gen_loss_df['Step'], gen_loss_df['Value'], alpha=0.2, c='#12b5cb')\n",
    "plt.plot(discrim_loss_df['Step'][:-(window_size - 1)], smoothed_discrim_loss, label='Discriminator loss', c='#e52592')\n",
    "plt.plot(gen_loss_df['Step'][:-(window_size - 1)], smoothed_gen_loss, label='Generator loss', c='#12b5cb')\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('GAN Loss')\n",
    "# log scale\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(GAN_LOSS_PLOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot perplexity\n",
    "PERPLEXITY_CSV_PATH = 'metrics/perplexity.csv'\n",
    "perplexity_df = pd.read_csv(PERPLEXITY_CSV_PATH)\n",
    "plt.plot(perplexity_df['Step'], perplexity_df['Value'], alpha=0.9, c='#e52592')\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('Mean Perplexity')\n",
    "#log scale\n",
    "plt.title('GAN Perplexity')\n",
    "plt.yscale('log')\n",
    "plt.savefig('figs/gan_perplexity_plot1.png')\n",
    "# log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " possible_hyperparams = {\n",
    "        'lr': [0.0001],\n",
    "        'batch_size': [16],\n",
    "        'temp': [1.0],\n",
    "        'seq_length': [15],\n",
    "    }\n",
    "\n",
    "lr_results = run_experiment(possible_hyperparams, \"lr\", num_epochs, train_sents, val_sents, encoding_manager, calc_perplexity, LOG_DIR_BASE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shaky_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
