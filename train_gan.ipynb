{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnhenryrudden/anaconda3/envs/shaky_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/johnhenryrudden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from embeddings import WordEmbeddingManager, create_embedding_dataloader\n",
    "import embeddings\n",
    "import utils\n",
    "from gan import Generator, Discriminator, train as train_gan\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/raw_train.txt'\n",
    "tokenized_sentences = utils.process_training_data(TRAIN_PATH)\n",
    "# Only use the first 10,000 sentences for now\n",
    "tokenized_sentences = tokenized_sentences[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sentence has 17 tokens\n"
     ]
    }
   ],
   "source": [
    "longest_sentence = max(tokenized_sentences, key=len)\n",
    "print(f'Longest sentence has {len(longest_sentence)} tokens')\n",
    "SEQ_LENGTH = len(longest_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from data/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "WORD2VEC_MODEL_PATH = 'data/word2vec.model'\n",
    "word2vec_manager = WordEmbeddingManager(WORD2VEC_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_embedding_dataloader(tokenized_sentences, word2vec_manager, seq_length=SEQ_LENGTH, batch_size=4, encoding_method=\"one_hot\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double check one hot encoding and decoding is working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding sentence: ['Such', 'a', 'nature', ',', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], with encoding method: one_hot\n",
      "Encoding sentence: ['First', 'Citizen', ':', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], with encoding method: one_hot\n",
      "Encoding sentence: ['I', 'speak', 'from', '<UNK>', '.', 'Nay', ',', 'more', ',', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], with encoding method: one_hot\n",
      "Encoding sentence: ['Nay', ',', 'let', 'them', 'follow', ':', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], with encoding method: one_hot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Such',\n",
       " 'a',\n",
       " 'nature',\n",
       " ',',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_first_sentence = batch[0]\n",
    "decoded_first_sentence = [word2vec_manager.decode_one_hot(encoded_token) for encoded_token in encoded_first_sentence]\n",
    "decoded_first_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([1., 0., 0.,  ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_encode = ['That', 'you', 'have', \"ta'en\", 'a', 'tardy', '<UNK>', 'here', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
    "encoded_sentence = [word2vec_manager.one_hot_encode(word) for word in sentence_to_encode]\n",
    "encoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That',\n",
       " 'you',\n",
       " 'have',\n",
       " \"ta'en\",\n",
       " 'a',\n",
       " 'tardy',\n",
       " '<UNK>',\n",
       " 'here',\n",
       " '.',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = [word2vec_manager.decode_one_hot(one_hot) for one_hot in encoded_sentence]\n",
    "decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "seq_length = SEQ_LENGTH \n",
    "\n",
    "# Generator first\n",
    "\n",
    "gen_input_dim = embeddings.EMBEDDING_SIZE\n",
    "gen_hidden_dim = 300\n",
    "\n",
    "# add 1 to output dim to account for padding token\n",
    "gen_output_dim = len(word2vec_manager._model.wv.key_to_index) + 1\n",
    "\n",
    "generator = Generator(input_size=gen_input_dim, hidden_size=gen_hidden_dim, output_size=gen_output_dim, seq_length=seq_length)\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "# Discriminator input is the same as the generator output (the generated next token probability distribution)\n",
    "discrim_input_dim = gen_output_dim\n",
    "discrim_hidden_dim = 100\n",
    "\n",
    "discriminator = Discriminator(input_dim=discrim_input_dim, hidden_dim=discrim_hidden_dim, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator has 2485755 parameters\n",
      "Discriminator has 2782901 parameters\n"
     ]
    }
   ],
   "source": [
    "discrim_params = list(discriminator.parameters())\n",
    "gen_params = list(generator.parameters())\n",
    "num_params_gen = sum([np.prod(p.size()) for p in gen_params])\n",
    "num_params_discrim = sum([np.prod(p.size()) for p in discrim_params])\n",
    "print(f'Generator has {num_params_gen} parameters')\n",
    "print(f'Discriminator has {num_params_discrim} parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 125/125 [00:13<00:00,  9.56it/s]\n",
      "Epoch 2/2: 100%|██████████| 125/125 [00:13<00:00,  9.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2\n",
    "batch_size = 4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "temperature = 1.0\n",
    "\n",
    "avg_g_loss, avg_d_loss = train_gan(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    tokenized_sentences=tokenized_sentences,\n",
    "    word2vec_manager=word2vec_manager,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    generator_input_features=gen_input_dim,  # Updated parameter name\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    temperature=temperature,\n",
    "    encoding_method=\"one_hot\",\n",
    "    debug=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fort', 'characters', 'HENRY', 'cuckolds', 'parliament', 'turn', 'Mars', 'appellant', 'elbow', 'prophecies', 'beggars', 'Conspirators', 'smock', 'Caius', 'shift', 'utterance', 'Pardon']\n",
      "['Seeking', 'spoke', 'enrich', \"'Whoop\", 'Westminster', 'fool', 'meet', 'suns', 'helping', 'transport', 'passion', \"'shall\", 'harder', 'mask', \"'love\", 'vouches', \"Thou'rt\"]\n",
      "['thy', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['ancient', 'CORIOLANUS', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['Stabb', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    noise = torch.randn(1, seq_length, gen_input_dim)\n",
    "    generated_data = generator(noise, temperature, should_sample=True)\n",
    "    generated_sentence = [word2vec_manager.index_to_word(word_index) for word_index in generated_data]\n",
    "    print(generated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shaky_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
